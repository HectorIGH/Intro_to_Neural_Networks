# -*- coding: utf-8 -*-
"""HW04_MLP_MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ACxo7K0Tz2d0WQVQ9HvbM_IyDI_C3vwO
"""

import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout
from keras.optimizers import RMSprop, Adadelta
from keras.utils import to_categorical, plot_model, model_to_dot, print_summary

from IPython.display import SVG

import matplotlib.pyplot as plt

from google.colab import files

batch_size = 86
num_classes = 10
epochs = 12

# Loading the data and split in training and test
(X_train, Y_train), (X_test, Y_test) = mnist.load_data()

# Showing the first image

plt.imshow(X_train[0])

# Reshaphing data to fit model

X_train = X_train.reshape(60000, 784)
X_test = X_test.reshape(10000, 784)

# Normalizing the data to train faster

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255
print(f'{X_train.shape[0]} train samples')
print(f'{X_test.shape[0]} test samples')

# Converting class vectors to binary class. One-hot encode target column
Y_train = to_categorical(Y_train, num_classes)
Y_test = to_categorical(Y_test, num_classes)
Y_train[0]

# Building the model

model = Sequential()
model.add(Dense(800, activation = 'relu', input_shape = (784, )))
#model.add(Dropout(0.2))
model.add(Dense(800, activation = 'relu'))
#model.add(Dropout(0.2))
model.add(Dense(num_classes, activation = 'softmax'))

# Compiling the model

model.compile(loss = 'categorical_crossentropy', optimizer = Adadelta(), metrics = ['accuracy'])

# Training the model

history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, verbose = 1, validation_data = (X_test, Y_test))

# Evaluating the model

score = model.evaluate(X_test, Y_test, verbose = 0)
print(f'Test loss: {score[0]}')
print(f'Test accuracy: {score[1]}')

# Plot the model
pltmodel = plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True, rankdir='TB')
pltmodel

#open('arquitectura.png', 'wb').write(pltmodel.data)
#files.download("arquitectura.png")

# Summary of the model
print_summary(model)

# Plot training and validation accuracy values
plt.plot(history.history['acc'])
plt.plot(history.history['val_acc'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc = 'upper left')
plt.figure(num=None, figsize=(18, 16), dpi=80, facecolor='w', edgecolor='k')
plt.show()

# Plot training and validation loss values
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc = 'upper left')
plt.figure(num=None, figsize=(18, 16), dpi=80, facecolor='w', edgecolor='k')
plt.show()

# Plot training loss and accuracy values
plt.plot(history.history['loss'])
plt.plot(history.history['acc'])
plt.title('Model loss and accuracy in training')
plt.ylabel('Values')
plt.xlabel('Epoch')
plt.legend(['Loss', 'Accuracy'], loc = 'upper right')
plt.show()

# Plot training and validation loss values
plt.plot(history.history['val_loss'])
plt.plot(history.history['val_acc'])
plt.title('Model loss and accuracy in validation')
plt.ylabel('Values')
plt.xlabel('Epoch')
plt.legend(['Loss', 'Accuracy'], loc = 'upper left')
plt.show()

